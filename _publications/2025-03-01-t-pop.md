---
title: "T-POP: Test-Time Personalization with Online Preference Feedback"
collection: publications
category: preprints
permalink: /publication/2025-03-01-t-pop
image: TPOP.png
authors: "Zikun Qu, Min Zhang, <b>Mingze Kong</b>, Xiang Li, Zhiwei Shang, Zhiyong Wang, Yikun Ban, Shuang Qiu, Yao Shu, Zhongxiang Dai"
excerpt: 'Personalizing large language models (LLMs) to individual user preferences is a critical step beyond generating generically helpful responses. However, current personalization methods are ill-suited for new users, as they typically require either slow, resource-intensive fine-tuning or a substantial amount of pre-existing user data, creating a significant cold-start problem. To address this challenge, we introduce a new paradigm for real-time personalization by learning from online pairwise preference feedback collected during text generation. We propose T-POP (Test-Time Personalization with Online Preference Feedback), a novel algorithm that synergistically combines test-time alignment with dueling bandits. Without updating the LLM parameters, T-POP steers the decoding process of a frozen LLM by learning a reward function online that captures user preferences. By leveraging dueling bandits, T-POP intelligently queries the user to efficiently balance between exploring their preferences and exploiting the learned knowledge to generate personalized text. Extensive experiments demonstrate that T-POP achieves rapid and data-efficient personalization, significantly outperforming existing baselines and showing consistent improvement with more user interactions.'
date: 2025-03-01
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2509.24696'
citation: 'Zikun Qu, Min Zhang, <b>Mingze Kong</b>, Xiang Li, Zhiwei Shang, Zhiyong Wang, Yikun Ban, Shuang Qiu, Yao Shu, Zhongxiang Dai. (2025). &quot;T-POP: Test-Time Personalization with Online Preference Feedback.&quot; <i>arXiv preprint arXiv:2509.24696</i>.'
---

